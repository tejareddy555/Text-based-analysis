{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c2b529-5bdd-4d37-a0b1-a233f88955a3",
   "metadata": {},
   "source": [
    "# INSTALLING NETWORKX PACKAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2087ad92-b6d5-41c9-814f-8b46648a3eec",
   "metadata": {},
   "source": [
    "Networkx is a Python library designed for working with complex networks or graphs. It offers a wide range of tools to examine the structure and behavior of networks, along with numerous graph theory algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7787b96-008a-4855-94ef-c2c3c3c0bcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in c:\\users\\abhil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deeffe4-349d-44af-8fa4-627bbe73cfea",
   "metadata": {},
   "source": [
    " # IMPORTING NECESSARY PACKAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811ac2d8-6096-443c-8eda-0654403ff66c",
   "metadata": {},
   "source": [
    "The cosine_distance function is part of the util module within the cluster package of the NLTK (Natural Language Toolkit) library. It facilitates the computation of cosine distance, which is a measure used to determine the similarity between vectors, commonly used in tasks related to clustering and comparing text similarity.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6610244a-8ff4-4f71-941f-91933b11fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #you can remove stop words for speed\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da3d30-1475-4b80-a7a5-7196ac745e54",
   "metadata": {},
   "source": [
    "# OPENING FILE AND SPLITTING INTO SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bdd91a9-414c-40ed-b125-cb20340fdaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of an ancient forest, where the thick canopy barely let the sunlight touch the moss-covered ground, a small stream meandered through the underbrush, its gentle babble a constant in the otherwise silent expanse\n",
      "This forest, untouched by time and human influence, held secrets from ages past, its trees standing as silent witnesses to the history that unfolded in its depths\n",
      "Among these towering sentinels, wildlife flourished in a delicate balance, a symphony of life that played out in the rustling leaves and the soft footfalls on the forest floor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"C:/Users/teja/OneDrive/Desktop/text1.txt\", \"r\")\n",
    "#This fileA contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989a22c0-7228-4c8b-8afa-b229cd32d42f",
   "metadata": {},
   "source": [
    "# PRINTING LIST OF SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9229d02e-5a08-4279-8b8e-391200eeed72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['In', 'the', 'heart', 'of', 'an', 'ancient', 'forest,', 'where', 'the', 'thick', 'canopy', 'barely', 'let', 'the', 'sunlight', 'touch', 'the', 'moss-covered', 'ground,', 'a', 'small', 'stream', 'meandered', 'through', 'the', 'underbrush,', 'its', 'gentle', 'babble', 'a', 'constant', 'in', 'the', 'otherwise', 'silent', 'expanse'], ['This', 'forest,', 'untouched', 'by', 'time', 'and', 'human', 'influence,', 'held', 'secrets', 'from', 'ages', 'past,', 'its', 'trees', 'standing', 'as', 'silent', 'witnesses', 'to', 'the', 'history', 'that', 'unfolded', 'in', 'its', 'depths'], ['Among', 'these', 'towering', 'sentinels,', 'wildlife', 'flourished', 'in', 'a', 'delicate', 'balance,', 'a', 'symphony', 'of', 'life', 'that', 'played', 'out', 'in', 'the', 'rustling', 'leaves', 'and', 'the', 'soft', 'footfalls', 'on', 'the', 'forest', 'floor.\\n']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06e3bd3-f702-488a-accb-5543c73aabf8",
   "metadata": {},
   "source": [
    "# FUNCTION TO CALCULATE SIMILARITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d935ec0b-56ea-489d-a8aa-77afbcf2a098",
   "metadata": {},
   "source": [
    "The sentence_similarity function measures the similarity between two sentences by using their word frequency vectors and the cosine distance metric. It initially converts the sentences to lowercase and then creates vectors that reflect the frequency of each unique word in the sentences. The function concludes by providing a similarity score derived from the cosine distance between these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d0bf2b0-70bf-4dfc-8e5b-87658d660d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "     # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "          vector1[all_words.index(w)] += 1\n",
    "     # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "          vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb37808-3e17-4c31-aa3a-0546ef8c3962",
   "metadata": {},
   "source": [
    "# CREATING SIMILARITY MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71a667-da85-4417-ac79-b61556dfdf2c",
   "metadata": {},
   "source": [
    "The similarity_matrix, a numpy array filled initially with zeros, serves to quantify the similarity between pairs of sentences. As the code progresses, it assesses every possible sentence pairing, employing the sentence_similarity function to evaluate their similarity and recording these scores within the matrix. It disregards the matrix's diagonal elements, where idx1 equals idx2, since these indicate a sentence being compared to itself. Upon completion, the code outputs the fully populated similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b2d9d23-17fb-408e-b1c6-349517366071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.26633806 0.51675233]\n",
      " [0.26633806 0.         0.20814536]\n",
      " [0.51675233 0.20814536 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "             if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "             similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b20cb8-a15a-45ef-8c7c-2f11a24a4bbc",
   "metadata": {},
   "source": [
    "# GETTING PAGERANK SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f0dbdee-1fed-424d-b827-6cf793e63db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.38835725455122294, 1: 0.2504316620240267, 2: 0.36121108342474983}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf56b0f0-0d09-4cea-8183-f63a79e44ec2",
   "metadata": {},
   "source": [
    "# SORTING SENTENCE BY PAGE RANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31483734-5c8f-4701-9e3b-6d95f3a1d06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.38835725455122294, ['In', 'the', 'heart', 'of', 'an', 'ancient', 'forest,', 'where', 'the', 'thick', 'canopy', 'barely', 'let', 'the', 'sunlight', 'touch', 'the', 'moss-covered', 'ground,', 'a', 'small', 'stream', 'meandered', 'through', 'the', 'underbrush,', 'its', 'gentle', 'babble', 'a', 'constant', 'in', 'the', 'otherwise', 'silent', 'expanse']), (0.36121108342474983, ['Among', 'these', 'towering', 'sentinels,', 'wildlife', 'flourished', 'in', 'a', 'delicate', 'balance,', 'a', 'symphony', 'of', 'life', 'that', 'played', 'out', 'in', 'the', 'rustling', 'leaves', 'and', 'the', 'soft', 'footfalls', 'on', 'the', 'forest', 'floor.\\n']), (0.2504316620240267, ['This', 'forest,', 'untouched', 'by', 'time', 'and', 'human', 'influence,', 'held', 'secrets', 'from', 'ages', 'past,', 'its', 'trees', 'standing', 'as', 'silent', 'witnesses', 'to', 'the', 'history', 'that', 'unfolded', 'in', 'its', 'depths'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\", ranked_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1040bf93-09a4-41c4-8176-6b39aa1b46a4",
   "metadata": {},
   "source": [
    "# PICKING TOP \"N\" SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12b7960a-89ac-4012-bfb1-c9054d84ef00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary?  2\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba10b8d-1eb0-4012-8eb4-a5784d761eef",
   "metadata": {},
   "source": [
    "# PRINTING SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8320302-edbc-4049-892e-56ad47de766d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " In the heart of an ancient forest, where the thick canopy barely let the sunlight touch the moss-covered ground, a small stream meandered through the underbrush, its gentle babble a constant in the otherwise silent expanse. Among these towering sentinels, wildlife flourished in a delicate balance, a symphony of life that played out in the rustling leaves and the soft footfalls on the forest floor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e2a580-80dc-437d-9954-4d90152d36cd",
   "metadata": {},
   "source": [
    "# INSTALLING NETWORKX PACKAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb59974-0e57-4aaa-92a0-bbec09be4779",
   "metadata": {},
   "source": [
    "\n",
    "Networkx is a Python library designed for constructing, modifying, and analyzing complex networks or graphs. It offers a comprehensive collection of tools for examining network structures and dynamics, alongside a variety of graph theory algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a2598c6-d57e-4079-aaf2-9a8346d7fa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in c:\\users\\abhil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ab027-dd09-4abf-8a8e-4d5a792e924c",
   "metadata": {},
   "source": [
    "# IMPORTING NECESSARY PACKAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a03dba9-2087-4fa9-af70-6d35454b06bb",
   "metadata": {},
   "source": [
    "The cosine_distance function is part of the util module within the cluster package of the NLTK (Natural Language Toolkit) library. It facilitates the computation of cosine distance, which is a measure used to determine the similarity between vectors, commonly used in tasks related to clustering and comparing text similarity.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf851a53-812a-479e-8f63-38731e309000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #you can remove stop words for speed\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3807eeb3-9ca1-4a80-8f5d-b311627c8391",
   "metadata": {},
   "source": [
    "# OPENING FILE AND SPLITTING INTO SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "784cbb55-a2e9-4252-a116-485e350c3c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of an ancient forest, where the thick canopy barely let the sunlight touch the moss-covered ground, a small stream meandered through the underbrush, its gentle babble a constant in the otherwise silent expanse\n",
      "This forest, untouched by time and human influence, held secrets from ages past, its trees standing as silent witnesses to the history that unfolded in its depths\n",
      "Among these towering sentinels, wildlife flourished in a delicate balance, a symphony of life that played out in the rustling leaves and the soft footfalls on the forest floor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"C:/Users/abhil/OneDrive/Desktop/text1.txt\", \"r\")\n",
    "#This fileA contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702fe000-9eab-4fd9-b122-d299cc8461c5",
   "metadata": {},
   "source": [
    "# PRINTING LIST OF SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63b5fe95-8db5-4600-b916-79340fc3232a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['In', 'the', 'heart', 'of', 'an', 'ancient', 'forest,', 'where', 'the', 'thick', 'canopy', 'barely', 'let', 'the', 'sunlight', 'touch', 'the', 'moss-covered', 'ground,', 'a', 'small', 'stream', 'meandered', 'through', 'the', 'underbrush,', 'its', 'gentle', 'babble', 'a', 'constant', 'in', 'the', 'otherwise', 'silent', 'expanse'], ['This', 'forest,', 'untouched', 'by', 'time', 'and', 'human', 'influence,', 'held', 'secrets', 'from', 'ages', 'past,', 'its', 'trees', 'standing', 'as', 'silent', 'witnesses', 'to', 'the', 'history', 'that', 'unfolded', 'in', 'its', 'depths'], ['Among', 'these', 'towering', 'sentinels,', 'wildlife', 'flourished', 'in', 'a', 'delicate', 'balance,', 'a', 'symphony', 'of', 'life', 'that', 'played', 'out', 'in', 'the', 'rustling', 'leaves', 'and', 'the', 'soft', 'footfalls', 'on', 'the', 'forest', 'floor.\\n']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edccb54-49db-47cb-ad9c-31133664dad2",
   "metadata": {},
   "source": [
    "# FUNCTION TO CALCULATE SIMILARITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd09b0a6-0133-4ca8-ae81-7f5c109ef9f4",
   "metadata": {},
   "source": [
    "\n",
    "The sentence_similarity function determines how similar two sentences are by analyzing their word frequency vectors and using cosine distance as the measurement. Initially, it converts the sentences to lowercase and constructs vectors that capture the frequency of every unique word in the sentences. The process concludes by computing a similarity score that reflects the cosine distance between these vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab6c77e4-c793-43a0-84f4-54d2fda68cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "     # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "          vector1[all_words.index(w)] += 1\n",
    "     # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "          vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50655782-71b3-4a6a-a2fd-1a9d4cdf3583",
   "metadata": {},
   "source": [
    "# CREATING SIMILARITY MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e57fe617-1073-4913-9e30-14ecf59098cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.26633806 0.51675233]\n",
      " [0.26633806 0.         0.20814536]\n",
      " [0.51675233 0.20814536 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "             if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "             similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb34d97-c483-4721-bc34-a93cac42dbbb",
   "metadata": {},
   "source": [
    "# GETTING PAGERANK SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26359963-275e-46b5-b4e1-1e3243df4ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.38835725455122294, 1: 0.2504316620240267, 2: 0.36121108342474983}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67997817-0e93-4fae-9986-4cad43b6d8b3",
   "metadata": {},
   "source": [
    "# SORTING SENTENCE BY PAGE RANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8691db74-0ae1-49e1-a728-73a90b2fc73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.38835725455122294, ['In', 'the', 'heart', 'of', 'an', 'ancient', 'forest,', 'where', 'the', 'thick', 'canopy', 'barely', 'let', 'the', 'sunlight', 'touch', 'the', 'moss-covered', 'ground,', 'a', 'small', 'stream', 'meandered', 'through', 'the', 'underbrush,', 'its', 'gentle', 'babble', 'a', 'constant', 'in', 'the', 'otherwise', 'silent', 'expanse']), (0.36121108342474983, ['Among', 'these', 'towering', 'sentinels,', 'wildlife', 'flourished', 'in', 'a', 'delicate', 'balance,', 'a', 'symphony', 'of', 'life', 'that', 'played', 'out', 'in', 'the', 'rustling', 'leaves', 'and', 'the', 'soft', 'footfalls', 'on', 'the', 'forest', 'floor.\\n']), (0.2504316620240267, ['This', 'forest,', 'untouched', 'by', 'time', 'and', 'human', 'influence,', 'held', 'secrets', 'from', 'ages', 'past,', 'its', 'trees', 'standing', 'as', 'silent', 'witnesses', 'to', 'the', 'history', 'that', 'unfolded', 'in', 'its', 'depths'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\", ranked_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8eee19-0467-4140-a293-d91e42d1ad83",
   "metadata": {},
   "source": [
    "# PICKING TOP \"N\" SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8846a3bf-3c21-4807-b029-edd0cd3195ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary?  2\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac185be-0bfd-48fe-90f0-845d3595cb9c",
   "metadata": {},
   "source": [
    "# PRINTING SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af5e4d98-8fdd-4853-b969-bd39d6f96f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " In the heart of an ancient forest, where the thick canopy barely let the sunlight touch the moss-covered ground, a small stream meandered through the underbrush, its gentle babble a constant in the otherwise silent expanse. Among these towering sentinels, wildlife flourished in a delicate balance, a symphony of life that played out in the rustling leaves and the soft footfalls on the forest floor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44189f79-5ff3-4eb5-a361-d9305d74cfbf",
   "metadata": {},
   "source": [
    "# TEXTFILE-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba30d9d3-5923-4ae4-bb06-7abc2b2cc250",
   "metadata": {},
   "source": [
    "# OPENING FILE AND SPLITTING INTO SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "668889b3-8d08-488a-b82c-411c6c83b37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amidst a bustling city, where skyscrapers stretched towards the sky like fingers reaching for the stars, there existed a small, secluded park\n",
      "This oasis of green was a stark contrast to the concrete jungle that surrounded it, offering a haven for those seeking solace from the relentless pace of urban life\n",
      "In this park, a tranquil pond mirrored the few fluffy clouds that adorned the otherwise clear blue sky, while willow trees whispered secrets to the gentle breeze that danced through their branches.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"C:/Users/abhil/OneDrive/Desktop/text2.txt\", \"r\")\n",
    "#This fileA contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159e071f-75ac-49fd-9f65-3ce9597f4b7c",
   "metadata": {},
   "source": [
    "# PRINTING LIST OF SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f13f854-f94a-407f-8874-c121a2994855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['Amidst', 'a', 'bustling', 'city,', 'where', 'skyscrapers', 'stretched', 'towards', 'the', 'sky', 'like', 'fingers', 'reaching', 'for', 'the', 'stars,', 'there', 'existed', 'a', 'small,', 'secluded', 'park'], ['This', 'oasis', 'of', 'green', 'was', 'a', 'stark', 'contrast', 'to', 'the', 'concrete', 'jungle', 'that', 'surrounded', 'it,', 'offering', 'a', 'haven', 'for', 'those', 'seeking', 'solace', 'from', 'the', 'relentless', 'pace', 'of', 'urban', 'life'], ['In', 'this', 'park,', 'a', 'tranquil', 'pond', 'mirrored', 'the', 'few', 'fluffy', 'clouds', 'that', 'adorned', 'the', 'otherwise', 'clear', 'blue', 'sky,', 'while', 'willow', 'trees', 'whispered', 'secrets', 'to', 'the', 'gentle', 'breeze', 'that', 'danced', 'through', 'their', 'branches.\\n']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b773ac9c-d9b5-46fc-98de-c155570fca95",
   "metadata": {},
   "source": [
    "# FUNCTION TO CALCULATE SIMILARITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8044bf12-3cb9-46c6-b149-bf57b5cc9a80",
   "metadata": {},
   "source": [
    "The sentence_similarity function assesses the similarity between two sentences by using their word frequency vectors and cosine distance as the measurement tool. It starts by converting the sentences to lowercase and then constructs vectors that denote the frequency of each unique word found in the sentences. In the end, the function provides a similarity score that is derived from the cosine distance between these two vectors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b02d14e-53b7-426f-ac3d-cf2845799391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "     # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "          vector1[all_words.index(w)] += 1\n",
    "     # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "          vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f04238-e948-4723-a965-d4f193e04038",
   "metadata": {},
   "source": [
    "# CREATING SIMILARITY MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef5a028-55a8-4369-a2a3-8a11a3046720",
   "metadata": {},
   "source": [
    "The similarity_matrix, a numpy array starting off with zeros, maps out the similarity levels between pairs of sentences. It goes through every sentence combination, uses the sentence_similarity function to determine the similarity for each pair, and then fills the similarity_matrix with these calculated scores. It overlooks the matrix's diagonal elements, where idx1 equals idx2, since this would only compare a sentence to itself. At the end, it outputs the completed similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f61e7d8-8a8b-486d-afce-bf7d6a0919d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.29834709 0.24806947]\n",
      " [0.29834709 0.         0.32071349]\n",
      " [0.24806947 0.32071349 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "             if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "             similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894cf49c-c4ea-4d54-8d60-b64850004a39",
   "metadata": {},
   "source": [
    "# GETTING PAGERANK SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38991e5b-f4fc-488b-82df-eef2adf87af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.31700154440863204, 1: 0.35454424577017063, 2: 0.32845420982119716}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd55c21f-ba79-43dd-8653-5827b68cd6df",
   "metadata": {},
   "source": [
    "# SORTING SENTENCE BY PAGE RANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fb759b7-7f89-4701-a194-01c575613ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.35454424577017063, ['This', 'oasis', 'of', 'green', 'was', 'a', 'stark', 'contrast', 'to', 'the', 'concrete', 'jungle', 'that', 'surrounded', 'it,', 'offering', 'a', 'haven', 'for', 'those', 'seeking', 'solace', 'from', 'the', 'relentless', 'pace', 'of', 'urban', 'life']), (0.32845420982119716, ['In', 'this', 'park,', 'a', 'tranquil', 'pond', 'mirrored', 'the', 'few', 'fluffy', 'clouds', 'that', 'adorned', 'the', 'otherwise', 'clear', 'blue', 'sky,', 'while', 'willow', 'trees', 'whispered', 'secrets', 'to', 'the', 'gentle', 'breeze', 'that', 'danced', 'through', 'their', 'branches.\\n']), (0.31700154440863204, ['Amidst', 'a', 'bustling', 'city,', 'where', 'skyscrapers', 'stretched', 'towards', 'the', 'sky', 'like', 'fingers', 'reaching', 'for', 'the', 'stars,', 'there', 'existed', 'a', 'small,', 'secluded', 'park'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\", ranked_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd288d0-ad49-4664-9bca-e2d5a2ac8e7b",
   "metadata": {},
   "source": [
    "# PICKING TOP \"N\" SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e1809fb-88d8-452f-9fbc-59cd3f44ef1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary?  2\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65985a7e-8708-466b-8a8a-57af72ecc86d",
   "metadata": {},
   "source": [
    "# PRINTING SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb04a3f9-fdea-496e-81c7-8e972ecbe5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " This oasis of green was a stark contrast to the concrete jungle that surrounded it, offering a haven for those seeking solace from the relentless pace of urban life. In this park, a tranquil pond mirrored the few fluffy clouds that adorned the otherwise clear blue sky, while willow trees whispered secrets to the gentle breeze that danced through their branches.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3b87b0-a926-4ea2-ac3b-59f3fff083ad",
   "metadata": {},
   "source": [
    "# TEXTFILE-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefb1561-3218-4ae5-ad2e-06a6555ff074",
   "metadata": {},
   "source": [
    "# OPENING FILE AND SPLITTING INTO SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f450d997-b196-40dd-bd5a-513110a96dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the rugged coastline, where the ocean's mighty waves met the land with a symphony of roars and whispers, stood a solitary lighthouse\n",
      "Its beacon, a guiding light in the veil of night, offered solace to the sailors braving the tumultuous sea\n",
      "The lighthouse, weathered by storms and the salt-laden air, bore the marks of its unyielding vigil over the treacherous waters, a sentinel of safety in the vast, unpredictable ocean.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"C:/Users/abhil/OneDrive/Desktop/text3.txt\", \"r\")\n",
    "#This fileA contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a3aa47-773c-42ec-b7b4-7ca77a286a96",
   "metadata": {},
   "source": [
    "# PRINTING LIST OF SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0234f16-8233-48d4-99ab-4b3966f18d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['On', 'the', 'rugged', 'coastline,', 'where', 'the', \"ocean's\", 'mighty', 'waves', 'met', 'the', 'land', 'with', 'a', 'symphony', 'of', 'roars', 'and', 'whispers,', 'stood', 'a', 'solitary', 'lighthouse'], ['Its', 'beacon,', 'a', 'guiding', 'light', 'in', 'the', 'veil', 'of', 'night,', 'offered', 'solace', 'to', 'the', 'sailors', 'braving', 'the', 'tumultuous', 'sea'], ['The', 'lighthouse,', 'weathered', 'by', 'storms', 'and', 'the', 'salt-laden', 'air,', 'bore', 'the', 'marks', 'of', 'its', 'unyielding', 'vigil', 'over', 'the', 'treacherous', 'waters,', 'a', 'sentinel', 'of', 'safety', 'in', 'the', 'vast,', 'unpredictable', 'ocean.\\n']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b808ac-1ea0-4b71-aad7-21388edfc0cb",
   "metadata": {},
   "source": [
    "# FUNCTION TO CALCULATE SIMILARITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3064f6-e70a-40af-bc11-fd111aeaeb5b",
   "metadata": {},
   "source": [
    "The sentence_similarity function assesses the similarity between two sentences by using their word frequency vectors and cosine distance as the measurement tool. It starts by converting the sentences to lowercase and then constructs vectors that denote the frequency of each unique word found in the sentences. In the end, the function provides a similarity score that is derived from the cosine distance between these two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06c0fd26-959d-4ac2-9987-4ccc5b757db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "     # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "          vector1[all_words.index(w)] += 1\n",
    "     # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "          vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74baed4-6f36-4fae-9a99-1467e3a58132",
   "metadata": {},
   "source": [
    "# CREATING SIMILARITY MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c389d8c4-8336-4949-b595-6de51c8a66b5",
   "metadata": {},
   "source": [
    "\n",
    "similarity_matrix is a numpy array initialized with zeros, where each element represents the similarity between two sentences. The code iterates through all combinations of sentences, calculates the similarity between each pair using the sentence_similarity function, and stores the resulting similarity scores in the similarity_matrix. The diagonal elements (where idx1 == idx2) are ignored, as they represent comparisons of a sentence with itself. The final similarity matrix is printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35d28a53-7ecc-4848-a445-7ef721992dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.43105272 0.50299545]\n",
      " [0.43105272 0.         0.56011203]\n",
      " [0.50299545 0.56011203 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "             if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "             similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3408a8cf-955a-4c8b-8458-5cc503ab0912",
   "metadata": {},
   "source": [
    "# GETTING PAGERANK SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0685900f-a196-4e8e-b918-e93cf78836f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.3147858025181738, 1: 0.33176553948092746, 2: 0.3534486580008985}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f24427-cfe6-4c8d-b7d9-89e3a3a7b1ed",
   "metadata": {},
   "source": [
    "# SORTING SENTENCE BY PAGE RANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c747e3f8-7667-4c67-92d6-051a88dfd2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.3534486580008985, ['The', 'lighthouse,', 'weathered', 'by', 'storms', 'and', 'the', 'salt-laden', 'air,', 'bore', 'the', 'marks', 'of', 'its', 'unyielding', 'vigil', 'over', 'the', 'treacherous', 'waters,', 'a', 'sentinel', 'of', 'safety', 'in', 'the', 'vast,', 'unpredictable', 'ocean.\\n']), (0.33176553948092746, ['Its', 'beacon,', 'a', 'guiding', 'light', 'in', 'the', 'veil', 'of', 'night,', 'offered', 'solace', 'to', 'the', 'sailors', 'braving', 'the', 'tumultuous', 'sea']), (0.3147858025181738, ['On', 'the', 'rugged', 'coastline,', 'where', 'the', \"ocean's\", 'mighty', 'waves', 'met', 'the', 'land', 'with', 'a', 'symphony', 'of', 'roars', 'and', 'whispers,', 'stood', 'a', 'solitary', 'lighthouse'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\", ranked_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62bbc41-65f4-46d1-b0d6-beb5b296de50",
   "metadata": {},
   "source": [
    "# PICKING TOP \"N\" SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce30dc4c-e9e8-4e59-ab8d-5075fc43d36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary?  2\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85bca22-7a2f-49b6-9f68-941c88dcbbe8",
   "metadata": {},
   "source": [
    "# PRINTING SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4ae1b0c-926e-48c2-8140-5f5d34ec1e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " The lighthouse, weathered by storms and the salt-laden air, bore the marks of its unyielding vigil over the treacherous waters, a sentinel of safety in the vast, unpredictable ocean.\n",
      ". Its beacon, a guiding light in the veil of night, offered solace to the sailors braving the tumultuous sea\n"
     ]
    }
   ],
   "source": [
    "### Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
